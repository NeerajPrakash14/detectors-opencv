{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.object_detection import non_max_suppression \n",
    "import numpy as np \n",
    "import imutils \n",
    "import cv2 \n",
    "import requests \n",
    "import time \n",
    "import argparse \n",
    "\n",
    "URL_EDUCATIONAL = \"http://things.ubidots.com\"\n",
    "URL_INDUSTRIAL = \"http://industrial.api.ubidots.com\"\n",
    "INDUSTRIAL_USER = True  # Set this to False if you are an educational user\n",
    "TOKEN = \"....\"  # Put here your Ubidots TOKEN\n",
    "DEVICE = \"detector\"  # Device where will be stored the result\n",
    "VARIABLE = \"people\"  # Variable where will be stored the result\n",
    "\n",
    "# Opencv pre-trained SVM with HOG people features \n",
    "HOGCV = cv2.HOGDescriptor()\n",
    "HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector(image):\n",
    "    '''\n",
    "    @image is a numpy array\n",
    "    '''\n",
    "\n",
    "    image = imutils.resize(image, width=min(400, image.shape[1]))\n",
    "    clone = image.copy()\n",
    "\n",
    "    (rects, weights) = HOGCV.detectMultiScale(image, winStride=(8, 8),\n",
    "                                              padding=(32, 32), scale=1.05)\n",
    "\n",
    "    # Applies non-max supression from imutils package to kick-off overlapped\n",
    "    # boxes\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "    result = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localDetect(image_path):\n",
    "    result = []\n",
    "    image = cv2.imread(image_path)\n",
    "    if len(image) <= 0:\n",
    "        print(\"[ERROR] could not read your local image\")\n",
    "        return result\n",
    "    print(\"[INFO] Detecting people\")\n",
    "    result = detector(image)\n",
    "\n",
    "    # shows the result\n",
    "    for (xA, yA, xB, yB) in result:\n",
    "        cv2.rectangle(image, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"result\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return (result, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cameraDetect(token, device, variable, sample_time=5):\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    init = time.time()\n",
    "\n",
    "    # Allowed sample time for Ubidots is 1 dot/second\n",
    "    if sample_time < 1:\n",
    "        sample_time = 1\n",
    "\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        frame = imutils.resize(frame, width=min(400, frame.shape[1]))\n",
    "        result = detector(frame.copy())\n",
    "\n",
    "        # shows the result\n",
    "        for (xA, yA, xB, yB) in result:\n",
    "            cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # Sends results\n",
    "        if time.time() - init >= sample_time:\n",
    "            print(\"[INFO] Sending actual frame results\")\n",
    "            # Converts the image to base 64 and adds it to the context\n",
    "            b64 = convert_to_base64(frame)\n",
    "            context = {\"image\": b64}\n",
    "            sendToUbidots(token, device, variable,\n",
    "                          len(result), context=context)\n",
    "            init = time.time()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def convert_to_base64(image):\n",
    "    image = imutils.resize(image, width=400)\n",
    "    img_str = cv2.imencode('.png', image)[1].tostring()\n",
    "    b64 = base64.b64encode(img_str)\n",
    "    return b64.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPeople(args):\n",
    "    image_path = args[\"image\"]\n",
    "    camera = True if str(args[\"camera\"]) == 'true' else False\n",
    "\n",
    "    # Routine to read local image\n",
    "    if image_path != None and not camera:\n",
    "        print(\"[INFO] Image path provided, attempting to read image\")\n",
    "        (result, image) = localDetect(image_path)\n",
    "        print(\"[INFO] sending results\")\n",
    "        # Converts the image to base 64 and adds it to the context\n",
    "        b64 = convert_to_base64(image)\n",
    "        context = {\"image\": b64}\n",
    "\n",
    "        # Sends the result\n",
    "        req = sendToUbidots(TOKEN, DEVICE, VARIABLE,\n",
    "                            len(result), context=context)\n",
    "        if req.status_code >= 400:\n",
    "            print(\"[ERROR] Could not send data to Ubidots\")\n",
    "            return req\n",
    "\n",
    "    # Routine to read images from webcam\n",
    "    if camera:\n",
    "        print(\"[INFO] reading camera images\")\n",
    "        cameraDetect(TOKEN, DEVICE, VARIABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPayload(variable, value, context):\n",
    "    return {variable: {\"value\": value, \"context\": context}}\n",
    "\n",
    "\n",
    "def sendToUbidots(token, device, variable, value, context={}, industrial=True):\n",
    "    # Builds the endpoint\n",
    "    url = URL_INDUSTRIAL if industrial else URL_EDUCATIONAL\n",
    "    url = \"{}/api/v1.6/devices/{}\".format(url, device)\n",
    "\n",
    "    payload = buildPayload(variable, value, context)\n",
    "    headers = {\"X-Auth-Token\": token, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    attempts = 0\n",
    "    status = 400\n",
    "\n",
    "    while status >= 400 and attempts <= 5:\n",
    "        req = requests.post(url=url, headers=headers, json=payload)\n",
    "        status = req.status_code\n",
    "        attempts += 1\n",
    "        time.sleep(1)\n",
    "    return req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argsParser():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-i\", \"--image\", default=None,\n",
    "                    help=\"path to image test file directory\")\n",
    "    ap.add_argument(\"-c\", \"--camera\", default=False,\n",
    "                    help=\"Set as true if you wish to use the camera\")\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-i IMAGE] [-c CAMERA]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\csc\\AppData\\Roaming\\jupyter\\runtime\\kernel-ed09c95a-46ba-4fc2-915f-bbafb8e3f07c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "args = argsParser()\n",
    "detectPeople(args)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "line_point1 = (400,0)\n",
    "line_point2 = (300,720)\n",
    "\n",
    "\n",
    "#in this case above the line and inbetween the two points is considered in\n",
    "\n",
    "ENTERED_STRING = \"ENTERED_THE_AREA\"\n",
    "LEFT_AREA_STRING = \"LEFT_THE_AREA\"\n",
    "NO_CHANGE_STRING = \"NOTHIN_HOMEBOY\"\n",
    "\n",
    "LOWEST_CLOSEST_DISTANCE_THRESHOLD = 100\n",
    "\n",
    "class Person:\n",
    "\n",
    "    positions = []\n",
    "\n",
    "    def __init__(self, position):\n",
    "        self.positions = [position]\n",
    "\n",
    "    def update_position(self, new_position):\n",
    "        self.positions.append(new_position)\n",
    "        if len(self.positions) > 100:\n",
    "            self.positions.pop(0)\n",
    "\n",
    "\n",
    "    def on_opposite_sides(self):\n",
    "        return ((self.positions[-2][0] > line_point1[0] and self.positions[-1][0] <= line_point1[0])\n",
    "                or (self.positions[-2][0] <= line_point1[0] and self.positions[-1][0] > line_point1[0]))\n",
    "\n",
    "    def did_cross_line(self):\n",
    "        if self.on_opposite_sides():\n",
    "            if self.positions[-1][0] > line_point1[0]:\n",
    "                return ENTERED_STRING\n",
    "            else:\n",
    "                return LEFT_AREA_STRING\n",
    "        else:\n",
    "            return NO_CHANGE_STRING\n",
    "\n",
    "    def distance_from_last_x_positions(self, new_position, x):\n",
    "        total = [0,0]\n",
    "        z = x\n",
    "        while z > 0:\n",
    "            if (len(self.positions) > z):\n",
    "                total[0] +=  self.positions[-(z+1)][0]\n",
    "                total[1] +=  self.positions[-(z+1)][1]\n",
    "            else:\n",
    "                x -= 1\n",
    "            z -= 1\n",
    "        if total[0] < 1 or total[1] < 1:\n",
    "            return abs(self.positions[0][0] - new_position[0]) + abs(self.positions[0][1] - new_position[1])\n",
    "        total[0] = total[0] / x\n",
    "        total[1] = total[1] / x\n",
    "\n",
    "        return abs(new_position[0] - total[0]) + abs(new_position[1] - total[1])\n",
    "\n",
    "\n",
    "def get_footage():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-v\", \"--video\", help=\"path to the video file\")\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    if args.get(\"video\", None) is None:\n",
    "        camera = cv2.VideoCapture(0)\n",
    "        time.sleep(0.25)\n",
    "        return camera\n",
    "\n",
    "    else:\n",
    "        return cv2.VideoCapture(0)\n",
    "\n",
    "def find_foreground_objects(background_model):\n",
    "    thresh = cv2.threshold(background_model, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    thresh = cv2.dilate(thresh, None, iterations=3)\n",
    "    thresh = cv2.erode(thresh, None, iterations=10)\n",
    "    cv2.imshow(\"Foreground Mfasdfaodel\", thresh)\n",
    "\n",
    "\n",
    "    cnts,hierarchy  = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return cnts\n",
    "\n",
    "def main():\n",
    "    path=r'C:\\Users\\csc\\Downloads\\walking.mp4'\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    \n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "    frame_count = 0\n",
    "    people_list = []\n",
    "    inside_count = 5\n",
    "\n",
    "    while True:\n",
    "\n",
    "        (grabbed, frame) = camera.read()\n",
    "        if not grabbed:\n",
    "            break\n",
    "        print(frame.shape)\n",
    "        frame = imutils.resize(frame, width=720)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        print(frame_count)\n",
    "\n",
    "        filtered_frame = cv2.GaussianBlur(frame, (21, 21), 0)\n",
    "        fgmask = fgbg.apply(filtered_frame)\n",
    "\n",
    "        foreground_objects = find_foreground_objects(fgmask)\n",
    "\n",
    "        \n",
    "        for c in foreground_objects:\n",
    "            if cv2.contourArea(c) < 5000:\n",
    "                continue\n",
    "\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            lowest_closest_distance = float(\"inf\")\n",
    "            X=math.ceil(((2*x)+w)/2)\n",
    "            Y=math.ceil(((2*y)+h)/2)\n",
    "            rectangle_center =(X,Y)\n",
    "            cv2.circle(frame, rectangle_center, 2, (0, 0, 255))\n",
    "            closest_person_index = None\n",
    "\n",
    "\n",
    "            for i in range(0, len(people_list)):\n",
    "                if people_list[i].distance_from_last_x_positions(rectangle_center, 5) < lowest_closest_distance:\n",
    "                    lowest_closest_distance = people_list[i].distance_from_last_x_positions(rectangle_center, 5)\n",
    "                    closest_person_index = i\n",
    "            if closest_person_index is not None:\n",
    "                if lowest_closest_distance < LOWEST_CLOSEST_DISTANCE_THRESHOLD:\n",
    "                    people_list[i].update_position(rectangle_center)\n",
    "                    change = people_list[i].did_cross_line()\n",
    "                    if change == ENTERED_STRING:\n",
    "                        inside_count += 1\n",
    "                    elif change == LEFT_AREA_STRING:\n",
    "                        inside_count -= 1\n",
    "                else:\n",
    "                    new_person = Person(rectangle_center)\n",
    "                    people_list.append(new_person)\n",
    "            else:\n",
    "                new_person = Person(rectangle_center)\n",
    "                people_list.append(new_person)\n",
    "\n",
    "\n",
    "        cv2.putText(frame, \"Number of people inside: {}\".format(inside_count), (10, 20),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.line(frame, line_point1, line_point2, (255, 0, 0), 2)\n",
    "        cv2.imshow(\"Security Feed\", frame)\n",
    "        cv2.imshow(\"Foreground Model\", fgmask)\n",
    "\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
